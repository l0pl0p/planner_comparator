import os
from dotenv import load_dotenv
from utils.azure_openai import client
from agents.prompt_persona import generate_legal_plan_prompt_persona
from agents.prolog_reasoner import generate_legal_plan_prolog
from agents.judge import judge_outputs

load_dotenv()

def llm_follow_up(system_prompt: str, user_prompt: str) -> str:
    response = client.chat.completions.create(
        model=os.getenv("AZURE_MODEL_FOLLOW_UP"),
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def main():
    subject = os.getenv("SUBJECT")

    print("ğŸ”¹ Generating research plans...")
    prompt_plan = generate_legal_plan_prompt_persona(subject)
    prolog_plan = generate_legal_plan_prolog(subject)

    print("\nğŸ”¸ Directly judging the research plans (Path 1)...")
    direct_plan_judgment = judge_outputs(prompt_plan, prolog_plan, judge_type="plans")

    print("\nğŸ”¹ Generating analyses from each research plan...")
    prompt_analysis = llm_follow_up(prompt_plan, subject)
    prolog_analysis = llm_follow_up(prolog_plan, subject)

    print("\nğŸ”¸ Judging plans via guided analyses (Path 2)...")
    analysis_based_judgment = judge_outputs(prompt_analysis, prolog_analysis, judge_type="analysis")

    # Clearly print your structured results
    print("\n=== Results Summary ===")
    print(f"ğŸ” Subject:\n{subject}\n")

    print("ğŸ—’ï¸ Prompt-based Research Plan:\n", prompt_plan, "\n")
    print("ğŸ—’ï¸ Prolog-based Research Plan:\n", prolog_plan, "\n")
    print("ğŸ§‘â€âš–ï¸ Direct Plan Judgment (Path 1):\n", direct_plan_judgment, "\n")

    print("ğŸ“š Prompt-guided Analysis:\n", prompt_analysis, "\n")
    print("ğŸ“š Prolog-guided Analysis:\n", prolog_analysis, "\n")
    print("ğŸ§‘â€âš–ï¸ Analysis-Based Judgment (Path 2):\n", analysis_based_judgment)

if __name__ == "__main__":
    main()
